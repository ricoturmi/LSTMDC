{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a data_set matrix\n",
    "def create_data_set(_data_set, _look_back=1, look_forward=10):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(_data_set) - _look_back - look_forward):\n",
    "        a = _data_set[i:(i + _look_back)]\n",
    "        data_x.append(a)\n",
    "        data_y.append([_data_set[i + j + _look_back] for j in range(look_forward)])\n",
    "    return np.array(data_x), np.array(data_y) \n",
    "\n",
    "# get the internal representation of the LSTM while predicting\n",
    "def get_internal_representation(sentence):\n",
    "    begin = sentence[-look_back-look_forward:-look_forward]\n",
    "    try:\n",
    "        new = np.array(begin).reshape(1,look_back,1)\n",
    "    except:\n",
    "        print(sentence, len(sentence))\n",
    "    seq = sequenceModel.predict(new)\n",
    "    return seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "look_back = 10\n",
    "look_forward = 1\n",
    "units = 50\n",
    "smoothing = '_s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('../LSTM/lb200_lf50_u200_e200_s.h5'.format(look_back, look_forward, units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('../LSTM/Models/lb{}_lf{}_u{}{}.h5'.format(look_back, look_forward, units, smoothing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Train_x_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    train_x = pickle.load(fp)\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Val_x_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    val_x = pickle.load(fp)\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Test_x_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    test_x = pickle.load(fp)\n",
    "    \n",
    "\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Train_y_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    train_y = pickle.load(fp)\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Val_y_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    val_y = pickle.load(fp)\n",
    "with open ('../Datapreprocessing/Data/Smoothing/Test_y_LB:{}{}'.format(look_back,smoothing), 'rb') as fp:\n",
    "    test_y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data_set\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_x = [scaler.fit_transform(np.array(l).reshape(-1,1)) for l in train_x if len(l) != 0]\n",
    "val_x = [scaler.fit_transform(np.array(l).reshape(-1,1)) for l in val_x if len(l) != 0]\n",
    "test_x = [scaler.fit_transform(np.array(l).reshape(-1,1)) for l in test_x if len(l) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model to return internal states\n",
    "weights = model.get_weights()\n",
    "\n",
    "sequenceModel = Sequential()\n",
    "sequenceModel.add(LSTM(units, input_shape=(look_back, 1), return_sequences=True))\n",
    "\n",
    "sequenceModel.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array([get_internal_representation(sentence) for sentence in train_x if len(sentence) > look_forward+look_back+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2775, 10, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = []\n",
    "tmp_y = []\n",
    "for i in range(len(train_x)):\n",
    "    for n in train_x[i]:\n",
    "#         print()\n",
    "        tmp_x.append(n)\n",
    "        tmp_y.append(train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27750, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.array(tmp_x, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(tmp_y, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = [get_internal_representation(sentence) for sentence in val_x if len(sentence) > look_forward+look_back+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_x = []\n",
    "tmp_y = []\n",
    "for i in range(len(val_x)):\n",
    "    for n in val_x[i]:\n",
    "#         print()\n",
    "        tmp_x.append(n)\n",
    "        tmp_y.append(val_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = np.array(tmp_x, dtype='float16')\n",
    "val_y = np.array(tmp_y, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [get_internal_representation(sentence) for sentence in test_x if len(sentence) > look_forward+look_back+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = []\n",
    "tmp_y = []\n",
    "for i in range(len(test_x)):\n",
    "    for n in test_x[i]:\n",
    "#         print()\n",
    "        tmp_x.append(n)\n",
    "        tmp_y.append(test_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array(tmp_x, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array(tmp_y, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870.0 920.0 1720.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.21082621082621"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = 0\n",
    "t2 = 0\n",
    "t3 = 0\n",
    "for i in test_y:\n",
    "    t1 += i[0]\n",
    "    t2 += i[1]\n",
    "    t3 += i[2]\n",
    "print(t1, t2, t3)\n",
    "sum([1 for i in test_y if i[1] == 1.])/len(test_y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if look_back == 100:\n",
    "#     val_x = np.append(val_x[:17400], val_x[17900:26600], axis = 0)\n",
    "#     val_y = np.append(val_y[:17400], val_y[17900:26600], axis = 0)\n",
    "#     train_x = np.append(train_x[:63600], train_x[79800:], axis = 0)\n",
    "#     train_y = np.append(train_y[:63600], train_y[79800:], axis = 0)\n",
    "#     test_x = np.append(test_x[:17400], test_x[17900:26600], axis = 0)\n",
    "#     test_y = np.append(test_y[:17400], test_y[17900:26600], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if look_back == 10:\n",
    "#     val_x = np.append(val_x[:420], val_x[440:650], axis = 0)\n",
    "#     val_y = np.append(val_y[:420], val_y[440:650], axis = 0)\n",
    "#     train_x = np.append(train_x[:3460], train_x[3580:5310], axis = 0)\n",
    "#     train_y = np.append(train_y[:3460], train_y[3580:5310], axis = 0)\n",
    "#     test_x = np.append(test_x[:420], test_x[440:650], axis = 0)\n",
    "#     test_y = np.append(test_y[:420], test_y[440:650], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if look_back == 100:\n",
    "#     val_x = np.append(val_x[:4200], val_x[4400:6500], axis = 0)\n",
    "#     val_y = np.append(val_y[:4200], val_y[4400:6500], axis = 0)\n",
    "#     train_x = np.append(train_x[:34600], train_x[35800:53100], axis = 0)\n",
    "#     train_y = np.append(train_y[:34600], train_y[35800:53100], axis = 0)\n",
    "#     test_x = np.append(test_x[:4200], test_x[4400:6500], axis = 0)\n",
    "#     test_y = np.append(test_y[:4200], test_y[4400:6500], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if look_back == 200:\n",
    "#     val_x = np.append(val_x[:8400], val_x[8800:13000], axis = 0)\n",
    "#     val_y = np.append(val_y[:8400], val_y[8800:13000], axis = 0)\n",
    "#     train_x = np.append(train_x[:69200], train_x[71600:106200], axis = 0)\n",
    "#     train_y = np.append(train_y[:69200], train_y[71600:106200], axis = 0)\n",
    "#     test_x = np.append(test_x[:8400], test_x[8800:13000], axis = 0)\n",
    "#     test_y = np.append(test_y[:8400], test_y[8800:13000], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], 1)\n",
    "# train_y = train_y.reshape(train_y.shape[0], train_y.shape[1])\n",
    "\n",
    "# val_x = val_x.reshape(val_x.shape[0], val_x.shape[1], 1)\n",
    "# val_y = val_y.reshape(val_y.shape[0], val_y.shape[1])\n",
    "\n",
    "# test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], 1)\n",
    "# test_y = test_y.reshape(test_y.shape[0], test_y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27750, 50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27750 samples, validate on 3530 samples\n",
      "Epoch 1/50\n",
      "27750/27750 [==============================] - 0s 14us/step - loss: 0.2253 - accuracy: 0.4757 - val_loss: 0.2136 - val_accuracy: 0.4448\n",
      "Epoch 2/50\n",
      "27750/27750 [==============================] - 0s 11us/step - loss: 0.2072 - accuracy: 0.4911 - val_loss: 0.2110 - val_accuracy: 0.4425\n",
      "Epoch 3/50\n",
      "27750/27750 [==============================] - 0s 10us/step - loss: 0.2055 - accuracy: 0.4949 - val_loss: 0.2110 - val_accuracy: 0.4414\n",
      "Epoch 4/50\n",
      "27750/27750 [==============================] - 0s 10us/step - loss: 0.2038 - accuracy: 0.5017 - val_loss: 0.2147 - val_accuracy: 0.4144\n",
      "Epoch 5/50\n",
      "27750/27750 [==============================] - 0s 10us/step - loss: 0.2025 - accuracy: 0.5067 - val_loss: 0.2158 - val_accuracy: 0.4125\n",
      "Epoch 6/50\n",
      "27750/27750 [==============================] - 0s 11us/step - loss: 0.2016 - accuracy: 0.5076 - val_loss: 0.2328 - val_accuracy: 0.3521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd286622550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = [EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=0, mode='auto')]\n",
    "\n",
    "diagnostic_classifier = Sequential()\n",
    "diagnostic_classifier.add(Dense(200, input_dim=units, activation='relu'))\n",
    "diagnostic_classifier.add(Dense(200, input_dim=units, activation='relu'))\n",
    "diagnostic_classifier.add(Dense(3))\n",
    "diagnostic_classifier.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "diagnostic_classifier.fit(train_x, train_y, epochs = 50, verbose=1, batch_size=512, callbacks = callback, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23  0.06  0.09  5.5 ]\n",
      " [ 0.27  0.56  0.36 56.3 ]\n",
      " [ 0.52  0.41  0.46 40.6 ]\n",
      " [ 0.38  0.36  0.34 34.2 ]]\n"
     ]
    }
   ],
   "source": [
    "test_predict = diagnostic_classifier.predict(test_x)\n",
    "\n",
    "accuracy_trump = sum([1 for i in range(len(test_predict)) if test_predict[i][0] == max(test_predict[i]) and test_y[i][0] ==  1.])/sum([1 for i in range(len(test_y)) if test_y[i][0] == 1.])*100\n",
    "accuracy_sarcasm = sum([1 for i in range(len(test_predict)) if test_predict[i][1] == max(test_predict[i]) and test_y[i][1] ==  1.])/sum([1 for i in range(len(test_y)) if test_y[i][1] == 1.])*100\n",
    "accuracy_baldwin = sum([1 for i in range(len(test_predict)) if test_predict[i][2] == max(test_predict[i]) and test_y[i][2] ==  1.])/sum([1 for i in range(len(test_y)) if test_y[i][2] == 1.])*100\n",
    "\n",
    "accuracy_avg = (accuracy_trump+accuracy_satire+accuracy_baldwin)/3\n",
    "\n",
    "y_true = []\n",
    "for item in test_y:\n",
    "    if item[0] == max(item):\n",
    "        y_true.append(0)\n",
    "    elif item[1] == max(item):\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(2)\n",
    "        \n",
    "y_pred = []\n",
    "for item in test_predict:\n",
    "    if item[0] == max(item):\n",
    "        y_pred.append(0)\n",
    "    elif item[1] == max(item):\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(2)\n",
    "\n",
    "target_names = ['Trump',  'Sarcasm','Baldwin']\n",
    "tmp = classification_report(y_true, y_pred, target_names=target_names)\n",
    "t = tmp.split('\\n')\n",
    "t = [i.split(' ') for i in t if i != '']\n",
    "t = [j for i in t for j in i if j != '']\n",
    "trump = t[5:8] + [round(accuracy_trump,1)]\n",
    "sarcasm = t[10:13] + [round(accuracy_sarcasm,1)]\n",
    "baldwin = t[15:18] + [round(accuracy_baldwin,1)]\n",
    "avg = t[-4:-1] + [round(accuracy_avg,1)]\n",
    "final = np.array([trump, sarcasm, baldwin, avg], dtype='float')\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
